{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPb4siY2QfrCoNUHKj/UdkQ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hsuancheyang/114-1-GenAI/blob/main/DNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# DNN 神經網路範例\n",
        "\n",
        "## 匯入基本相關函式庫"
      ],
      "metadata": {
        "id": "zF9EqJZbkyT9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "BBcb7Rf5uT-i"
      },
      "outputs": [],
      "source": [
        "from keras.models import Sequential, load_model\n",
        "from keras.layers import Dense, Dropout\n",
        "import numpy as np\n",
        "import os"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 準備訓練資料\n",
        "1000筆資料，每筆資料中有20個特徵值。\n",
        "\n",
        "每個特徵值為0~1間的隨機浮點數。\n",
        "\n",
        "標註：分類一（0） 與 分類二（1），也是隨機亂給。"
      ],
      "metadata": {
        "id": "jcSDZnSVloSp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = np.random.rand(1000, 20)  # 1000 samples, 20 features each\n",
        "train_labels = np.random.randint(0, 2, size=(1000,))  # Binary classification (0 or 1)\n",
        "\n",
        "# 列印第0~第5筆資料與其對應的「標註」\n",
        "print(f'Training data[0~5]: \\n{train_data[0:5]}')\n",
        "print(f'Training labels[0~5]: \\n{train_labels[0:5]}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zpKQRRkSujQg",
        "outputId": "b19d7e90-60b4-4884-b530-249de1fdae9c"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training data[0~5]: \n",
            "[[3.98518316e-01 4.73129314e-01 7.76152343e-01 7.66902860e-01\n",
            "  8.94900887e-01 5.92796607e-01 4.84496995e-01 9.77894780e-01\n",
            "  3.26614357e-01 6.38597481e-01 3.38426311e-01 8.14146406e-01\n",
            "  5.77303392e-01 2.33563419e-01 6.87741897e-01 3.02315644e-01\n",
            "  6.25016350e-01 8.19970848e-01 3.75464412e-01 5.37621180e-01]\n",
            " [8.84114482e-01 7.16643008e-01 5.06788929e-02 2.75241781e-01\n",
            "  3.91885210e-01 3.93435554e-01 9.83770776e-01 8.92308515e-01\n",
            "  4.98987586e-01 5.02975116e-01 6.48705304e-01 3.50077347e-01\n",
            "  9.03935489e-01 9.14165344e-01 2.81048001e-01 1.77071736e-01\n",
            "  2.35413601e-01 3.72099546e-01 2.33087579e-01 4.46784664e-01]\n",
            " [2.98374750e-01 4.69222575e-01 7.12944948e-01 4.41456729e-01\n",
            "  1.75297100e-01 9.58893697e-01 8.14129776e-02 1.08162858e-01\n",
            "  8.57633410e-01 5.92973396e-02 5.97826002e-01 5.75859089e-01\n",
            "  4.29773957e-03 2.83577685e-01 7.76257210e-02 1.43622663e-01\n",
            "  6.67808255e-01 7.92260233e-01 5.13246806e-01 7.91642398e-04]\n",
            " [7.46269822e-01 9.54261034e-01 7.78579844e-01 9.88832958e-01\n",
            "  1.55288289e-01 5.81113258e-01 5.25745982e-02 5.28280233e-01\n",
            "  9.89332995e-01 2.40503962e-01 3.64143661e-01 5.99883825e-01\n",
            "  8.05996299e-01 3.57244990e-01 4.54934869e-01 2.12092277e-01\n",
            "  9.20969607e-02 5.19542783e-01 7.63327547e-01 5.68921176e-01]\n",
            " [8.68606466e-01 7.23984928e-01 7.01119691e-01 9.48209660e-01\n",
            "  1.00760788e-02 6.41029650e-01 3.38168503e-01 3.82121904e-02\n",
            "  2.84314503e-01 9.25622533e-01 9.23578827e-01 9.42282078e-01\n",
            "  1.31821544e-01 9.90367039e-02 1.50631578e-01 5.53321912e-01\n",
            "  1.51468270e-01 5.20742165e-01 7.47783490e-01 4.38503861e-01]]\n",
            "Training labels[0~5]: \n",
            "[1 0 1 1 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 輸入的特徵有20個\n",
        "### 最後輸出的標註有2個（0 or 1）\n",
        "\n",
        "1. 建立一個簡單的神經網路串列，第一層使用全連接的神經網路 `Dense (DNN)`。\n",
        "\n",
        "> 內含：64個神經元。使用ReLu激活函式。\n",
        "\n",
        "2. 加入一個Dropout：\n",
        "\n",
        "> Dropout：此為用於防止過度擬合的正則規化技術。在訓練過程中，它會在每次更新時隨機將部分輸入單元設為 0。\n",
        "\n",
        "> (0.5)：此參數代表 Dropout 率，意指前一層中 50% 的神經元將在每次訓練迭代中被隨機剔除。透過隨機剔除神經元，網路對單一神經元的依賴性降低，從而提升對未見數據的泛化能力。\n",
        "\n",
        "3. 新增另一個含32個神經元的全連接層，採用ReLU激活函數。\n",
        "\n",
        "4. 添加最終全連接層，輸出維度為 output_dim（此處為 2）。採用 softmax 激活函數，該函數能輸出類別間的概率分佈，適用於多類分類問題。"
      ],
      "metadata": {
        "id": "tbzLp4s8xJJF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# DNN model definition\n",
        "input_dim = 20  # input dimension to match synthetic data\n",
        "output_dim = 2  # output dimension for binary classification\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "# Add layers to the model\n",
        "model.add(Dense(64, activation='relu', input_shape=(input_dim,)))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(32, activation='relu'))\n",
        "# Add more layers as needed\n",
        "model.add(Dense(output_dim, activation='softmax'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gf7sbM1pumOY",
        "outputId": "784d8b8f-f3cf-4108-cf23-a9cbb2e27308"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/core/dense.py:93: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 編譯神經網路模型：\n",
        "\n",
        "1. model.compile(...): 此函式用於配置模型以進行訓練。\n",
        "2. optimizer=『adam』: 此參數指定訓練過程中使用的優化演算法。Adam 是一種廣受歡迎且高效的優化器。\n",
        "3. loss= 'sparse_categorical_crossentropy': 此處定義損失函數。當標籤為整數（此處為 0 或 1）時，應採用稀疏類別交叉熵損失函數，此函數適用於二元分類問題。\n",
        "4. metrics=[『accuracy』]: 此參數指定訓練與測試階段的評估指標。『accuracy』 將衡量模型正確預測類別的頻率。"
      ],
      "metadata": {
        "id": "gefGTS2C0Nza"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile the model\n",
        "model.compile(\n",
        "    optimizer='adam',\n",
        "    loss='sparse_categorical_crossentropy',  # Use sparse categorical crossentropy for integer labels\n",
        "    metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "OAAUEekvusVJ"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "model.fit(...): 此函式使用提供的資料訓練模型。\n",
        " * train_data: 此為模型將學習的訓練資料（特徵）。\n",
        " * train_labels: 此為 train_data 的對應標籤（分類）。\n",
        " * epochs=10：此參數指定模型將完整遍歷訓練資料集的次數。本例中將循環處理資料10次。\n",
        " * batch_size=32：此參數定義每次梯度更新的樣本數量。訓練資料將被劃分為每批32個樣本的批次，模型權重將在處理完每批資料後更新。\n"
      ],
      "metadata": {
        "id": "dpSVMwfZ1GM4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "model.fit(train_data, train_labels, epochs=10, batch_size=32)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WBroTfqsuwIw",
        "outputId": "fd8e9b1a-2e57-440c-a83c-a9a6989f6691"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.5254 - loss: 0.7169\n",
            "Epoch 2/10\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4556 - loss: 0.7166\n",
            "Epoch 3/10\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4995 - loss: 0.7014\n",
            "Epoch 4/10\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.4995 - loss: 0.7025\n",
            "Epoch 5/10\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5100 - loss: 0.6987\n",
            "Epoch 6/10\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5331 - loss: 0.6896\n",
            "Epoch 7/10\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5060 - loss: 0.6917\n",
            "Epoch 8/10\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5429 - loss: 0.6927\n",
            "Epoch 9/10\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5534 - loss: 0.6874 \n",
            "Epoch 10/10\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5229 - loss: 0.6856 \n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7c3b96049490>"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the trained model\n",
        "model_dir = 'saved_models'\n",
        "model_path = os.path.join(model_dir, 'dnn_model.h5')\n",
        "model.save(model_path)\n",
        "print(f\"模型已保存至 {model_path}\")\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 335
        },
        "id": "ZFOtNts0uzFY",
        "outputId": "cb6dffb9-a57e-4596-a560-ecad19764caf"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "模型已保存至 saved_models/dnn_model.h5\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m1,344\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │         \u001b[38;5;34m2,080\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m)              │            \u001b[38;5;34m66\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,344</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">66</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m10,472\u001b[0m (40.91 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">10,472</span> (40.91 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m3,490\u001b[0m (13.63 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,490</span> (13.63 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m6,982\u001b[0m (27.28 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">6,982</span> (27.28 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#\n",
        "# Generate some synthetic test data for prediction\n",
        "#\n",
        "new_data = np.random.rand(10, 20)\n",
        "print(\"\\n新的測試數據：\")\n",
        "print(new_data)\n",
        "\n",
        "# Predict using the loaded model\n",
        "print(\"\\n開始進行預測...\")\n",
        "predictions = model.predict(new_data)\n",
        "print(\"原始預測結果 (機率分佈)：\")\n",
        "print(predictions)\n",
        "\n",
        "predicted_classes = np.argmax(predictions, axis=1) # axis=1 表示在每個樣本的機率分佈中取最大值\n",
        "print(\"\\n預測的類別標籤 (0 或 1)：\")\n",
        "print(predicted_classes)\n",
        "\n",
        "# 為了更好地理解，我們手動為每個樣本顯示預測結果\n",
        "print(\"\\n每個樣本的預測結果：\")\n",
        "for i, (prob, cls) in enumerate(zip(predictions, predicted_classes)):\n",
        "    print(f\"  樣本 {i+1}: 預測機率 = {prob}, 預測類別 = {cls}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rR9DtRiru5y3",
        "outputId": "ade3f4f5-465f-45a2-c452-16a477551fef"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "新的測試數據：\n",
            "[[0.86347884 0.06033171 0.93764377 0.51939837 0.43341539 0.83017314\n",
            "  0.35225854 0.90019706 0.09924296 0.50142386 0.23691591 0.51570904\n",
            "  0.49499783 0.34358389 0.11110142 0.05553029 0.79101457 0.7841049\n",
            "  0.5165522  0.05100846]\n",
            " [0.33162996 0.19833296 0.89306267 0.20967086 0.41249406 0.7855817\n",
            "  0.57662314 0.24505117 0.88079845 0.73484144 0.46563229 0.37551528\n",
            "  0.67689508 0.33508262 0.70648945 0.66122111 0.99631679 0.9502268\n",
            "  0.20063639 0.68756302]\n",
            " [0.46548491 0.22457713 0.0782265  0.57941674 0.1408073  0.08773819\n",
            "  0.8213534  0.4884904  0.42236536 0.95897612 0.97067182 0.73532454\n",
            "  0.01887388 0.66677145 0.54542298 0.6166649  0.0130004  0.98331552\n",
            "  0.93315777 0.39011684]\n",
            " [0.01323737 0.74156359 0.04966213 0.23743457 0.76103469 0.60511701\n",
            "  0.08718056 0.39558485 0.11019133 0.2666486  0.12116495 0.35654944\n",
            "  0.9525466  0.55311596 0.62399706 0.3175274  0.87296879 0.19750069\n",
            "  0.21326869 0.71725427]\n",
            " [0.1744422  0.44850515 0.02246775 0.62574977 0.84198664 0.17637172\n",
            "  0.59715354 0.15331767 0.86450502 0.15874521 0.34191288 0.21361265\n",
            "  0.16840849 0.68386635 0.99782906 0.15417455 0.37683833 0.53333034\n",
            "  0.36576899 0.18159876]\n",
            " [0.42060464 0.44230554 0.97697278 0.03201955 0.73678266 0.10236343\n",
            "  0.0043326  0.77267092 0.70472671 0.46862362 0.4963355  0.39788316\n",
            "  0.07619908 0.18401013 0.12807746 0.94441003 0.01199454 0.43689376\n",
            "  0.46325654 0.66276948]\n",
            " [0.3951081  0.80565668 0.94743991 0.83055883 0.93692229 0.45077674\n",
            "  0.72475778 0.79995385 0.78245063 0.41044303 0.39603303 0.23052187\n",
            "  0.48792052 0.16247764 0.59576629 0.35971723 0.82060461 0.95281721\n",
            "  0.56612568 0.95173252]\n",
            " [0.56340399 0.36753356 0.36789348 0.52707379 0.16268148 0.25555995\n",
            "  0.31440575 0.1304874  0.74266417 0.56344025 0.74746975 0.10045723\n",
            "  0.75183333 0.44273065 0.254039   0.19048182 0.86651439 0.97755661\n",
            "  0.23863805 0.98906922]\n",
            " [0.11214666 0.16732152 0.9378969  0.89998558 0.54533867 0.38299078\n",
            "  0.71197163 0.83671143 0.1064884  0.76127935 0.86444642 0.88432316\n",
            "  0.84993256 0.54130917 0.54567964 0.39961082 0.11158873 0.25644538\n",
            "  0.18798351 0.91771698]\n",
            " [0.15125663 0.07776697 0.49759693 0.32887588 0.65007339 0.31219769\n",
            "  0.81460412 0.74371709 0.99742484 0.58537644 0.74367955 0.80936861\n",
            "  0.01628296 0.34422954 0.59258792 0.46210497 0.15936981 0.3244568\n",
            "  0.09385101 0.43439735]]\n",
            "\n",
            "開始進行預測...\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "原始預測結果 (機率分佈)：\n",
            "[[0.4972153  0.5027847 ]\n",
            " [0.49368748 0.50631255]\n",
            " [0.49327806 0.506722  ]\n",
            " [0.436702   0.563298  ]\n",
            " [0.45581838 0.54418164]\n",
            " [0.5005464  0.49945357]\n",
            " [0.46832117 0.5316787 ]\n",
            " [0.49955955 0.5004404 ]\n",
            " [0.44302365 0.5569764 ]\n",
            " [0.48604286 0.5139571 ]]\n",
            "\n",
            "預測的類別標籤 (0 或 1)：\n",
            "[1 1 1 1 1 0 1 1 1 1]\n",
            "\n",
            "每個樣本的預測結果：\n",
            "  樣本 1: 預測機率 = [0.4972153 0.5027847], 預測類別 = 1\n",
            "  樣本 2: 預測機率 = [0.49368748 0.50631255], 預測類別 = 1\n",
            "  樣本 3: 預測機率 = [0.49327806 0.506722  ], 預測類別 = 1\n",
            "  樣本 4: 預測機率 = [0.436702 0.563298], 預測類別 = 1\n",
            "  樣本 5: 預測機率 = [0.45581838 0.54418164], 預測類別 = 1\n",
            "  樣本 6: 預測機率 = [0.5005464  0.49945357], 預測類別 = 0\n",
            "  樣本 7: 預測機率 = [0.46832117 0.5316787 ], 預測類別 = 1\n",
            "  樣本 8: 預測機率 = [0.49955955 0.5004404 ], 預測類別 = 1\n",
            "  樣本 9: 預測機率 = [0.44302365 0.5569764 ], 預測類別 = 1\n",
            "  樣本 10: 預測機率 = [0.48604286 0.5139571 ], 預測類別 = 1\n"
          ]
        }
      ]
    }
  ]
}